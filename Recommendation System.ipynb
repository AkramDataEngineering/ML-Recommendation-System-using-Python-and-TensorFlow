{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cfc342-8619-4ad8-a55a-04e952f33a5f",
   "metadata": {},
   "source": [
    "## Recommendation System using Python and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed442b54-1e18-4fe4-8365-83511f476cc0",
   "metadata": {},
   "source": [
    "Recommendation systems are the invisible engine behind the success of platforms like Netflix, Amazon, Spotify, and YouTube. They personalize your experience by suggesting what to watch, buy, or listen to next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607beca-2702-446e-93f5-b98ea636c81e",
   "metadata": {},
   "source": [
    "## Recommendation System using Python and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fcc24-a8e7-430e-a0d2-4d5ada9ecdc5",
   "metadata": {},
   "source": [
    "We’ll use a real Netflix dataset containing titles, content types, languages, and viewing hours. By the end, you’ll have a deep learning model that can answer questions like: If someone liked Wednesday, what else might they enjoy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c25cb-886c-40d0-b57a-59e732577d70",
   "metadata": {},
   "source": [
    "## Step 1: Load and Understand the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e8961-f640-416e-9b1f-5ace715c76c6",
   "metadata": {},
   "source": [
    "We’re using a Netflix 2023 dataset with the following fields:\n",
    "\n",
    "* Title\n",
    "* Available Globally?\n",
    "* Release Date\n",
    "* Hours Viewed\n",
    "* Language Indicator\n",
    "* Content Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771e4a7-ded6-4096-b8c7-c7d5605fc2db",
   "metadata": {},
   "source": [
    "Let’s load the data and move forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc0da8f-54b6-423f-be60-146b341a6d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>Language Indicator</th>\n",
       "      <th>Content Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Agent: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>81,21,00,000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ginny &amp; Georgia: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>66,51,00,000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Glory: Season 1 // 더 글로리: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>62,28,00,000</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>50,77,00,000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queen Charlotte: A Bridgerton Story</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>50,30,00,000</td>\n",
       "      <td>English</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Available Globally? Release Date  \\\n",
       "0            The Night Agent: Season 1                 Yes   2023-03-23   \n",
       "1            Ginny & Georgia: Season 2                 Yes   2023-01-05   \n",
       "2   The Glory: Season 1 // 더 글로리: 시즌 1                 Yes   2022-12-30   \n",
       "3                  Wednesday: Season 1                 Yes   2022-11-23   \n",
       "4  Queen Charlotte: A Bridgerton Story                 Yes   2023-05-04   \n",
       "\n",
       "   Hours Viewed Language Indicator Content Type  \n",
       "0  81,21,00,000            English         Show  \n",
       "1  66,51,00,000            English         Show  \n",
       "2  62,28,00,000             Korean         Show  \n",
       "3  50,77,00,000            English         Show  \n",
       "4  50,30,00,000            English        Movie  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "netflix = pd.read_csv(\"netflix_content.csv\")\n",
    "\n",
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5050e-911f-4e65-92b3-db9efa6a0185",
   "metadata": {},
   "source": [
    "This data is rich for content-based filtering, even without user behaviour data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84994ef-cdff-4d9b-99ae-11fc4d8d9dbb",
   "metadata": {},
   "source": [
    "## Step 2: Clean and Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542c8f4-a385-4878-a99f-bd306e112553",
   "metadata": {},
   "source": [
    "Before modelling, we need to convert the data into a numerical format. So, let’s clean and preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02691bae-aed1-4507-9089-f4b24e750bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24812 entries, 0 to 24811\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                24812 non-null  object\n",
      " 1   Available Globally?  24812 non-null  object\n",
      " 2   Release Date         8166 non-null   object\n",
      " 3   Hours Viewed         24812 non-null  object\n",
      " 4   Language Indicator   24812 non-null  object\n",
      " 5   Content Type         24812 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "netflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c40aa2-3672-4f97-9be2-70eea7e0de7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Available Globally?</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Hours Viewed</th>\n",
       "      <th>Language Indicator</th>\n",
       "      <th>Content Type</th>\n",
       "      <th>Content_ID</th>\n",
       "      <th>Language_ID</th>\n",
       "      <th>ContentType_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Agent: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>812100000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ginny &amp; Georgia: Season 2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>665100000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Glory: Season 1 // 더 글로리: 시즌 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>622800000</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Show</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday: Season 1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>507700000</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queen Charlotte: A Bridgerton Story</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>503000000</td>\n",
       "      <td>English</td>\n",
       "      <td>Movie</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Available Globally? Release Date  \\\n",
       "0            The Night Agent: Season 1                 Yes   2023-03-23   \n",
       "1            Ginny & Georgia: Season 2                 Yes   2023-01-05   \n",
       "2   The Glory: Season 1 // 더 글로리: 시즌 1                 Yes   2022-12-30   \n",
       "3                  Wednesday: Season 1                 Yes   2022-11-23   \n",
       "4  Queen Charlotte: A Bridgerton Story                 Yes   2023-05-04   \n",
       "\n",
       "   Hours Viewed Language Indicator Content Type  Content_ID  Language_ID  \\\n",
       "0     812100000            English         Show           0            0   \n",
       "1     665100000            English         Show           1            0   \n",
       "2     622800000             Korean         Show           2            3   \n",
       "3     507700000            English         Show           3            0   \n",
       "4     503000000            English        Movie           4            0   \n",
       "\n",
       "   ContentType_ID  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix[\"Hours Viewed\"] = netflix[\"Hours Viewed\"].str.replace(\",\", \"\" , regex = False).astype(\"int64\")\n",
    "\n",
    "#Dropping Rows with Missing titles or duplicate titles\n",
    "\n",
    "netflix.dropna(subset= [\"Title\"], inplace = True)\n",
    "netflix.drop_duplicates(subset= [\"Title\"], inplace = True)\n",
    "\n",
    "# Create Simple content IDs for Tensorflow Embeddings\n",
    "netflix[\"Content_ID\"] = netflix.reset_index().index.astype(\"int32\")\n",
    "\n",
    "#Encode \"Language Indicator\"  and \"Content Type\"\n",
    "netflix[\"Language_ID\"] = netflix[\"Language Indicator\"].astype(\"category\").cat.codes\n",
    "netflix[\"ContentType_ID\"] = netflix[\"Content Type\"].astype(\"category\").cat.codes\n",
    "\n",
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f984c-b3a9-412c-9089-acba0aaacda7",
   "metadata": {},
   "source": [
    "TensorFlow doesn’t work with strings; it needs numbers. So, we converted content metadata into categorical encodings for use in embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd989933-d653-43cc-a657-6fedbab181b1",
   "metadata": {},
   "source": [
    "## Step 3: Build a Neural Recommendation Model Using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242946d-3abc-491a-be1b-989890a5fdd5",
   "metadata": {},
   "source": [
    "We will use embeddings to capture complex relationships between features like language, type, and content ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286d17ef-8525-4539-b933-296f77c6ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c6fdd9-fd70-433e-81bf-51e0c4df12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It counts the number of unique content IDs in the \"XXX\" column of the netflix DataFrame.\n",
    "\n",
    "num_contents = netflix[\"Content_ID\"].nunique()\n",
    "num_languages = netflix[\"Language_ID\"].nunique()\n",
    "num_types = netflix[\"ContentType_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedb978f-e22c-45b2-9687-24c805cb0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is TensorFlow / Keras code used when building a neural network model, \n",
    "#especially in functional API style. It defines an input layer to the model.\n",
    "\n",
    "content_input = layers.Input(shape=(1,), dtype= tf.int32 , name= \"content_id\")\n",
    "language_input = layers.Input(shape=(1,), dtype= tf.int32 , name= \"language_id\")\n",
    "type_input = layers.Input(shape=(1,), dtype= tf.int32 , name= \"content_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250a1d0-3e3a-4add-9a73-9a25bb2f7f8a",
   "metadata": {},
   "source": [
    "* Creating an embedding layer\n",
    "*  Applying it to the input (content_input)\n",
    "*   Producing a dense vector representation of the content_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ab18ec-ba15-42f5-adc4-2ee26a5e764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_embedding = layers.Embedding(input_dim= num_contents+1 , output_dim= 32)(content_input)\n",
    "language_embedding = layers.Embedding(input_dim= num_languages+1 , output_dim= 8)(language_input)\n",
    "type_embedding = layers.Embedding(input_dim= num_types+1 , output_dim= 4)(type_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761558ec-7e57-4477-bba6-1f75364b45e5",
   "metadata": {},
   "source": [
    "This line flattens the output of the embedding layer — turning a multi-dimensional tensor into a 1D vector per sample — so it can be passed into dense (fully connected) layers or other downstream layers.\n",
    "* Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b22578-ccc3-405a-a8d9-9bc6c942e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_vec = layers.Flatten()(content_embedding)\n",
    "language_vec = layers.Flatten()(language_embedding)\n",
    "type_vec = layers.Flatten()(type_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a6f8ba1-2297-4747-bdb8-feeaf23411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = layers.Concatenate()([content_vec , language_vec , type_vec])\n",
    "\n",
    "X = layers.Dense(64,activation= \"relu\")(combined)\n",
    "X = layers.Dense(32 , activation = \"relu\")(X)\n",
    "\n",
    "output = layers.Dense(num_contents , activation= \"softmax\")(X)\n",
    "\n",
    "\n",
    "model = Model(inputs = [content_input , language_input , type_input] , outputs = output)\n",
    "model.compile(optimizer = \"adam\" , loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad1a99-3fad-4df4-9565-53ed4263360c",
   "metadata": {},
   "source": [
    "Embeddings compress high-dimensional categorical data (like content IDs or languages) into dense vectors where similar values cluster together. It will allow our model to learn which content is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c0a63-f54e-4925-af51-592728ec5970",
   "metadata": {},
   "source": [
    "## Step 4: Train the Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec98d33-dc92-4497-befe-7ae85dcd45ea",
   "metadata": {},
   "source": [
    "We’ll use the content itself as the label so the model learns to predict content from its features. This is a self-supervised learning approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2fead0-4485-4192-aaf5-b38f6b63d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 9.8788\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 9.8661\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.0015 - loss: 9.7094\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.0105 - loss: 8.3892\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.1127 - loss: 6.1094\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.3409 - loss: 4.0164\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.5962 - loss: 2.3226\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.8068 - loss: 1.0820\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9338 - loss: 0.3923\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9821 - loss: 0.1256\n",
      "Epoch 11/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9961 - loss: 0.0429\n",
      "Epoch 12/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9994 - loss: 0.0169\n",
      "Epoch 13/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0100\n",
      "Epoch 14/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 15/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x207455866b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        x = {\"content_id\": netflix[\"Content_ID\"],\n",
    "            \"language_id\": netflix[\"Language_ID\"],\n",
    "             \"content_type\": netflix[\"ContentType_ID\"]\n",
    "            },\n",
    "        y = netflix[\"Content_ID\"],epochs = 15 , batch_size = 64\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee115d7-ca5d-4d5d-b36a-2e35e6d775b5",
   "metadata": {},
   "source": [
    "It structures the embedding space based on real metadata. Similar content will have similar embeddings. It will allow recommendations based on closeness in vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f2a37-6ea4-4894-ae40-78ba31d15a28",
   "metadata": {},
   "source": [
    "## Step 5: Recommend Similar Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce4bc8-b4c4-416c-9c46-aea58e8ac698",
   "metadata": {},
   "source": [
    "Once the model is trained, you can input any show/movie and get a list of similar titles. Here’s how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8ce9dc7-9e77-436c-a732-4d266a9441e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_similar(content_title , top_k = 5):\n",
    "    content_row = netflix[netflix[\"Title\"].str.contains(content_title , case = False , na= False)].iloc[0]\n",
    "    content_id = content_row[\"Content_ID\"]\n",
    "    language_id = content_row[\"Language_ID\"]\n",
    "    content_type_id = content_row[\"ContentType_ID\"]\n",
    "\n",
    "    predictions = model.predict({\n",
    "        \"content_id\" : np.array([content_id]),\n",
    "        \"language_id\" : np.array([language_id]),\n",
    "        \"content_type\" : np.array([content_type_id]),\n",
    "    })\n",
    "\n",
    "    top_indices = predictions[0].argsort()[-top_k-1: ][::-1]\n",
    "    recommendations = netflix[netflix[\"Content_ID\"].isin(top_indices)]\n",
    "    return recommendations[[\"Title\" , \"Language Indicator\" , \"Content Type\", \"Hours Viewed\"]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae739da-76ff-4d56-a768-def40c4e1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Language Indicator</th>\n",
       "      <th>Content Type</th>\n",
       "      <th>Hours Viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday: Season 1</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>507700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>ALVINNN!!! And the Chipmunks: Season 2</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>29300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>Justice Served: Season 1</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>5400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>Superstition: Season 1</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>2900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>Berserk: Season 1 // ベルセルク: シーズン1</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Show</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>Last Tango in Halifax: Season 4</td>\n",
       "      <td>English</td>\n",
       "      <td>Show</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title Language Indicator Content Type  \\\n",
       "3                         Wednesday: Season 1            English         Show   \n",
       "657    ALVINNN!!! And the Chipmunks: Season 2            English         Show   \n",
       "3364                 Justice Served: Season 1            English         Show   \n",
       "4948                   Superstition: Season 1            English         Show   \n",
       "9940        Berserk: Season 1 // ベルセルク: シーズン1           Japanese         Show   \n",
       "10906         Last Tango in Halifax: Season 4            English         Show   \n",
       "\n",
       "       Hours Viewed  \n",
       "3         507700000  \n",
       "657        29300000  \n",
       "3364        5400000  \n",
       "4948        2900000  \n",
       "9940         500000  \n",
       "10906        400000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_similar(\"Wednesday\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288ffeb6-4344-4f59-9908-5d0ec989089d",
   "metadata": {},
   "source": [
    "The embeddings map each content item into a 32-dimensional space. Items that are closer in this space are likely to be similar in:\n",
    "\n",
    "* Language\n",
    "* Content Type\n",
    "* Viewership Pattern\n",
    "- So, even without user feedback, your model can say: “Hey, these titles are kind of alike.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a4948-d56c-4e59-a5b7-35f8c6363531",
   "metadata": {},
   "source": [
    "## Final Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d191784-6e7c-408a-ac75-2ecea12808a3",
   "metadata": {},
   "source": [
    "With just content features and deep learning, you’ve now built a powerful, user-independent recommendation system using TensorFlow. This not only showcases your ability to work with embeddings and real-world data but also lays the foundation for building smarter, scalable, and personalized AI systems, just like the ones used by Netflix and Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00844321-7ffa-44e2-bc9f-65040828d38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
